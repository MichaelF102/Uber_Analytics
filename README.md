ğŸš• Uber Ride Analytics â€” End-to-End Data Pipeline Using Linux Project

An end-to-end data analytics pipeline that demonstrates how raw CSV data can be transformed into clean, structured insights using Bash, SQLite, and Streamlit â€” without relying on heavy frameworks.

This project mirrors real-world data engineering workflows: messy data, command-line processing, analytics persistence, and interactive dashboards.

ğŸ“Œ Project Overview

Pipeline Flow

Raw CSV (Kaggle)
   â†“
Bash Data Cleaning
   â†“
Shell-Based Analytics
   â†“
SQLite Storage
   â†“
Streamlit Dashboard


Domain: Ride bookings & mobility analytics
Dataset Source: Kaggle (Uber Ride Analytics)

ğŸ“¥ Stage 1 â€” Dataset Acquisition

Dataset downloaded from Kaggle

Raw CSV contained:

Missing values

Inconsistent formats

Noise & invalid records

Mimics how data is typically received in real-world pipelines

ğŸ§¹ Stage 2 â€” Data Cleaning (Bash)

Script: dataclean.sh

Cleaning Operations

Removed invalid & duplicate rows

Trimmed whitespace

Normalized NULL values

Fixed negative numeric values

Capped extreme outliers

Standardized categorical text

Final sanity cleanup

Why Bash?

Fast streaming processing

Works in constrained environments

Scales to large CSV files

Reproducible & automatable

ğŸ“Š Stage 3 â€” Exploratory Analytics (Shell)

Script: analytics.sh
Tools: Bash + AWK

Analytics Generated

Booking status distribution

Vehicle demand patterns

Pickup & drop location popularity

Revenue metrics

Cancellation analysis

Demonstrates that meaningful analytics can be performed without Python or Pandas.

ğŸ—„ï¸ Stage 4 â€” Analytics Storage (SQLite)

Script: analytics_to_sql.sh

Features

SQLite database creation

Normalized analytics tables

Pre-aggregated metrics

Fast downstream access

Why SQLite?

Lightweight & portable

Zero configuration

Ideal for analytics dashboards

Production-friendly for read-heavy workloads

ğŸ“ˆ Stage 5 â€” Interactive Dashboard (Streamlit)

Framework: Streamlit
Visuals: Plotly
Backend: SQLite + CSV

Dashboard Capabilities

SQL-backed KPIs (fast & stable)

CSV-backed deep analytics

Interactive filters

Time trends & correlations

Clean, modular architecture

Optional code visibility toggle for data cleaning logic

ğŸ—‚ï¸ Project Structure
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ncr_ride_bookings_dirty.csv
â”‚   â””â”€â”€ ncr_ride_bookings_clean.csv
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ dataclean.sh
â”‚   â”œâ”€â”€ analytics.sh
â”‚   â””â”€â”€ analytics_to_sql.sh
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ assets/
â”‚
â”œâ”€â”€ analytics.db
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup & Usage
1ï¸âƒ£ Clone Repository
git clone https://github.com/yourusername/uber-ride-analytics.git
cd uber-ride-analytics

2ï¸âƒ£ Run Data Cleaning
bash scripts/dataclean.sh

3ï¸âƒ£ Run Analytics
bash scripts/analytics.sh

4ï¸âƒ£ Store Results in SQLite
bash scripts/analytics_to_sql.sh

5ï¸âƒ£ Launch Dashboard
pip install -r requirements.txt
streamlit run dashboard/app.py

ğŸ“¦ Requirements

See requirements.txt

Core dependencies:

Streamlit

Pandas

Plotly

SQLite

Pillow
